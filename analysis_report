Rapport d'analyse - Projet Titanic
1. Introduction
Le naufrage du Titanic en 1912 est l'un des événements maritimes les plus tragiques de l'histoire, causant la mort de plus de 1500 personnes. L'analyse de ces données historiques permet d'examiner les facteurs qui ont pu influencer la probabilité de survie des passagers.

Ce rapport présente une analyse complète des données disponibles, suivie d'une modélisation prédictive pour déterminer les facteurs ayant le plus influencé la survie des passagers.

2. Exploration des données

2.1 Description des variables
Les données du Titanic contiennent des informations sur les passagers telles que leur nom, leur sexe, leur âge, leur classe, leur nationalité et leur ticket. Parmi les variables importantes, nous avons :

survived : Indique si un passager a survécu ou non (0 = non, 1 = oui).
gender : Sexe du passager.
age : Âge du passager.
class : La classe du passager (1ère, 2e, 3e).
fare : Le tarif payé pour le billet.
country : Nationalité du passager.
embarked : Port d'embarquement (S = Southampton, C = Cherbourg, Q = Queenstown).

2.2 Visualisations exploratoires
Pour mieux comprendre les données, voici quelques visualisations initiales :

Distribution des âges des passagers : Cette visualisation permet de comprendre la répartition des âges parmi les passagers. En général, il y avait une majorité d'adultes jeunes (entre 20 et 40 ans) à bord.

Répartition des passagers par sexe : La majorité des passagers étaient des hommes, ce qui influencera peut-être notre modélisation.

Répartition des passagers par classe : La plupart des passagers appartenaient à la troisième classe, suivie par la deuxième et la première classe.

Graphiques supplémentaires :
Taux de survie par sexe et par classe : Cette visualisation montre que les femmes, particulièrement en première classe, avaient un taux de survie beaucoup plus élevé que les hommes.
3. Préparation des données
3.1 Gestion des valeurs manquantes
Certaines colonnes contenaient des valeurs manquantes, notamment la colonne "age" et "fare". Nous avons procédé à :

Imputer la médiane pour l'âge.
Imputer la moyenne pour le prix du billet (fare).
Imputer la nationalité inconnue par "Unknown".


2.3 Visualisations principales

Répartition des âges des passagers : La distribution montre que la majorité des passagers avaient entre 20 et 40 ans.
Répartition par sexe : Les hommes représentaient une majorité des passagers.

Taux de survie par sexe et par classe :
Les femmes avaient un taux de survie plus élevé que les hommes.
Les passagers de première classe avaient plus de chances de survivre que ceux des classes inférieures.

2.4 Conclusion de l'exploration
Les premiers résultats montrent que le sexe, la classe du billet et l'âge sont des facteurs clés influençant les chances de survie des passagers.


3 Préparation des données
Imputation des valeurs manquantes et transformation des variables
Standardisation : Les colonnes numériques age et fare ont été standardisées pour avoir une échelle comparable.
Encodage des variables catégorielles : Les colonnes comme gender, class, country ont été encodées en variables numériques par un encodage one-hot.
Rééquilibrage des classes avec SMOTE : Étant donné que la classe survived était déséquilibrée, la méthode SMOTE a été utilisée pour rééquilibrer les classes.

3.1 Séparation des données
Nous avons séparé les données en deux ensembles : 80% des données pour l'entraînement et 20% pour le test. Cela permet d'entraîner les modèles sur une partie des données tout en conservant un ensemble pour évaluer la performance des modèles sur des données non vues.

3.2 Modèles testés
Nous avons testé plusieurs modèles de machine learning pour prédire la survie des passagers :

3.3 Modélisation
Modèles testés
Régression Logistique
Random Forest
XGBoost
Voting Classifier (Ensemble) : Un modèle combinant les prédictions de la régression logistique, Random Forest, XGBoost, et K-Nearest Neighbors (KNN).
Validation croisée et sélection des hyperparamètres
Les modèles ont été optimisés via RandomizedSearchCV pour sélectionner les meilleurs hyperparamètres. La validation croisée à 5 plis (StratifiedKFold) a été utilisée pour évaluer la robustesse des modèles.

Métriques d'évaluation
Accuracy : La proportion des prédictions correctes.
Matrice de confusion : Pour visualiser les prédictions correctes et incorrectes par classe.
Rapport de classification : Précision, rappel et F1-score pour chaque classe.
Courbe ROC et AUC : Mesure de la capacité du modèle à discriminer entre les survivants et non-survivants.

4. Résultats
Comparaison des modèles
Modèle	              Accuracy	Précision (Survivants)	Rappel (Survivants)	AUC
Régression Logistique	0.7557	    0.62	                    0.60	        0.78
Random Forest	        0.7760	    0.66	                    0.61	        0.79
XGBoost	              0.7624	    0.64	                    0.59	        0.80
Voting Classifier	    0.7851	    0.68	                    0.63	        0.80

Analyse des résultats

Régression Logistique :

Le modèle a une bonne performance globale (75.57% d'accuracy), mais il sous-prédit les survivants (classe 1), avec une précision de 62%.
L'AUC de 0.78 indique une bonne capacité de séparation entre les classes.

Random Forest :

Ce modèle montre une meilleure capacité à identifier les survivants que la régression logistique, avec un rappel de 61%.
L'AUC est de 0.79, ce qui montre qu'il est légèrement supérieur à la régression logistique.

XGBoost :

XGBoost affiche des performances similaires à Random Forest en termes d'accuracy (76.24%) et d'AUC (0.80).
Il semble bien équilibré entre précision et rappel.

Voting Classifier :

Le classificateur par vote a les meilleures performances globales avec une accuracy de 78.51% et un AUC de 0.80.
Il combine efficacement les avantages des autres modèles pour offrir une prédiction plus robuste.

Courbes ROC pour les différents modèles
Une comparaison des courbes ROC montre que le Voting Classifier et XGBoost ont les meilleurs AUC (0.80), indiquant une meilleure capacité à discriminer les classes.

5. Conclusion et recommandations
Résumé des résultats
Le Voting Classifier a montré les meilleures performances globales, avec une précision de 78.51% et un AUC de 0.80. Il combine les forces des autres modèles tout en maintenant un bon équilibre entre précision et rappel pour la classe des survivants. XGBoost, en tant que modèle individuel, s'est également bien comporté avec un AUC similaire.

Recommandations
Ensembles plus robustes : Envisager d'autres modèles d'ensemble comme le Gradient Boosting ou des versions améliorées de XGBoost pour améliorer encore la détection des survivants.
Tuning d'hyperparamètres supplémentaires : Ajuster davantage les hyperparamètres des modèles, en particulier pour XGBoost et Random Forest, pourrait permettre d'améliorer la performance.
Analyse approfondie des caractéristiques : Il serait intéressant d'examiner l'importance des variables (feature importance) pour mieux comprendre les facteurs les plus influents dans la prédiction.
Enrichir les données : inclure d'autres variables qui pourraient être pertinentes pour la survie (par exemple, les informations sur les cabines ou les relations familiales).

6 Considérations éthiques
Il est important de noter que certains modèles ont pu être biaisés par des facteurs tels que le sexe ou la classe sociale, ce qui reflète les normes sociales de l'époque plutôt que des critères purement techniques.

